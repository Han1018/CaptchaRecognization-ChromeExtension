# -*- coding: utf-8 -*-
"""predict_webAPI

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13TDy2orMf8u08OPjpH3Z2MD-HxYgkNq5
"""

#!pip install captcha
import re
import uuid
from matplotlib.pyplot import imshow
import os
import io
from io import BytesIO
import time
import numpy as np  
from PIL import Image  
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import glob 
import datetime
import cv2
from keras.models import load_model
import tensorflow as tf
from flask import Flask, jsonify, request,Response
import base64
from captcha.image import ImageCaptcha
import random
from flask_cors import CORS
import requests
from io import BytesIO
app = Flask(__name__)
model = '';
ALPHABET = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']
all_set=ALPHABET#+alphabet
dict_all={}
label_chr={}
for i, c in enumerate(all_set):
    dict_all[c]=i
CHAR_SET_LEN=len(all_set)
for i in range(CHAR_SET_LEN):
    label_chr[i]=all_set[i]

def remove_edge_picture(imagepath):

    image = cv2.imread(imagepath, 0)
    # cv2.imshow('原',image)
    height, width = image.shape
    corner_list = [image[0,0] < 127,
                    image[height-1, 0] < 127,
                    image[0, width-1]<127,
                    image[ height-1, width-1] < 127
                    ]
    if sum(corner_list) >= 3:
        os.remove(imagepath)
        return 1
    return 0

def resplit_with_parts(image, parts):
#    image = cv2.imread(imagepath, 0)
    height, width = image.shape
    split_image=[]
    # 将图片重新分裂成parts部分
    step = width//parts     # 步长
    start = 0             # 起始位置
    
    #只留第一個其他步要
    for i in range(parts):
        split_image.append(image[:, start:start+step])
        start += step
        
    return split_image

def resplit(image):
#    image = cv2.imread(connect_image, 0)
    #沒找到圖片就返回
    split_image=[]
    part=1
    if image is None:
        print('是空的')
        return
    height, width = image.shape
    #4個黏在一起
    if width >= 85:    
        part=4
    #3個黏在一起    
    elif width >= 55:
        part=3
    #2個黏在一起        
    elif width >= 35:
        part=2     
    else:
        split_image.append(image)
        return split_image,part

    split_image=resplit_with_parts(image, part)        
    return split_image,part

def sort_contours(cnts, method="left-to-right"):
    # initialize the reverse flag and sort index
    reverse = False
    i = 0

    # handle if we need to sort in reverse
    if method == "right-to-left" or method == "bottom-to-top":
        reverse = True

    # handle if we are sorting against the y-coordinate rather than
    # the x-coordinate of the bounding box
    if method == "top-to-bottom" or method == "bottom-to-top":
        i = 1

    # construct the list of bounding boxes and sort them from top to
    # bottom
    boundingBoxes = [cv2.boundingRect(c) for c in cnts]
    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),
        key=lambda b:b[1][i], reverse=reverse))

    # return the list of sorted contours and bounding boxes
    return (cnts)

def split_picture(image,edge_image):
    PIC_LENGTH=32
    label_index=0
    return_split=[]
    last_X=0
    last_Y=0
    imshow(image)
    # 用edge_detect的影像 做圖像分割判斷，提取单个字符
    contours, hierarchy = cv2.findContours(edge_image,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
#    print(len(contours))
    #對返回的各點座標執行排序
    contours=sort_contours(contours, method="left-to-right")
    times=0
    for i, cnt in enumerate(contours):
        # 最小的外接矩形
        x, y, w, h = cv2.boundingRect(cnt)
        
        #檢測座標點不是空的&& 不能與前一個座標長寬重複(用edge_image找分割點，目前會有重複文提)
        if (x != 0) and (y != 0) and (last_X!=x or last_Y!=y) :
            last_X=x
            last_Y=y
            part_image=image[y:y+h, x:x+w]
            height, width = part_image.shape
            
            #排除雜訊可能 => width<=20 & height <=20 or height<=14
            if(width <=20 and height<=20 or height<=14):
                continue
            
            #切割圖片，包含黏在一起的。
            #返回的part:圖片個數(int), split_image為[]，放圖片的np array。
            split_image,part=resplit(part_image)
            
            for i in range(part):
                resize_image=cv2.resize(split_image[i],(PIC_LENGTH,PIC_LENGTH))
                resize_image=resize_image.reshape(PIC_LENGTH,PIC_LENGTH,1)
                
                label_index=times
                #圖片放置到 各字的資料夾
                try:
                    #將切割資料分別加入LIST
                    return_split.append(resize_image)
#                  cv2.imwrite('./test_splited_pic/{}__{}.jpg'.format(label_index,uuid.uuid1()), split_image[i])
                    times+=1
                except :
                    print('err',times)
    return return_split

def readFile_txt(textUrl):
    f= open(textUrl, mode='r')
    return f.read()

def random_captcha_text(char_set=all_set,captcha_size=4):
    captcha_text=''
    for i in range(captcha_size):
        c=random.choice(char_set)
        captcha_text+=c
    return captcha_text

def gen_captcha_text_image(captcha_text):
    image=ImageCaptcha(width=135,height=39)
#    captcha_text=random_captcha_text()
    captcha_text=''.join(captcha_text)
    captcha=image.generate(captcha_text)
    captcha_image=Image.open(captcha)
    captcha_image=np.array(captcha_image)
    return captcha_image

def get_data_generate():
    count=20
    errtime=0
    text_list=[]
    image_list=[]
    for i in range(count):
        text = random_captcha_text()
        image=gen_captcha_text_image(text)
        #將PIL格式的image轉成CV2的圖片格式
        image=np.asarray(image)
        image_list.append(image)
        text_list.append(text)
    
    return image_list,text_list

def get_data():
    test_data_count =20
    x=[]
    y=[]
    i=0
    pic_route='train/'

    #抓出檔案的圖片&label
    for i in range(test_data_count):
        file_image=pic_route+str(i)+'.jpg'
        if(i==test_data_count):
            break
        x.append(np.array(Image.open(file_image)).reshape(39,135,3))
        # y.append(readFile_txt(file_label))
        i=i+1

    return x , y

def clean_noise(data_list):
#    src:https://blog.csdn.net/qq_38410428/article/details/93046099
    for i in range(len(data_list)):
        #消除造點的參數皆為預設，細節看上面的網址
        data_list[i]=cv2.fastNlMeansDenoisingColored(data_list[i],None,10,10,7,21)
    return data_list

def clean_noise_black(data_list):
    # 設置卷積核 
    kernel1 = np.ones((2, 2), np.uint8)
    edge_kernel = np.ones((2, 2), np.uint8) 
    edge_list=[]
    for i in range(len(data_list)):
#        消除造點的參數皆為預設，細節看上面的網址
        data_list[i]=cv2.medianBlur(data_list[i], 3)
#        data_list[i]=cv2.medianBlur(data_list[i], 3)
#        原文網址：https://kknews.cc/code/63qzkxl.html
        data_list[i]= cv2.morphologyEx(data_list[i], cv2.MORPH_OPEN, kernel1)
        data_list[i]= cv2.morphologyEx(data_list[i], cv2.MORPH_CLOSE, kernel1)
        edge_list.append(cv2.morphologyEx(data_list[i], cv2.MORPH_GRADIENT, edge_kernel))
    
    return data_list,edge_list

def gray_thresh(data_list):
    
    for k in range(len(data_list)):
        # 將圖片轉灰階
        gray = cv2.cvtColor(data_list[k], cv2.COLOR_BGR2GRAY)
        # print(gray.shape)
        # gray = gray.reshape(39,135,1)
        # 将图片的边缘变为白色
        height, width = gray.shape
        for i in range(width):
            gray[0, i] = 255
            gray[height-1, i] = 255
        for j in range(height):
            gray[j, 0] = 255
            gray[j, width-1] = 255
            
        # 圖片經thresh成黑白
        #用 OTSU threshold 自訂義閥值, 所以不用指定
        ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)  #方法选择为THRESH_OTSU
        #185 is threshhold, 255 is highest value
#        ret,thresh1 = cv2.threshold(gray, 185, 255, cv2.THRESH_BINARY)
        data_list[k]=thresh1
        
    return data_list

def arrange_split_array(pretrain_list):
    target_len=4
    len_of_list=len(pretrain_list)
    if(len_of_list==target_len):
        return pretrain_list[:],target_len
    
    elif(len_of_list>target_len):
        return pretrain_list[:target_len],len_of_list
    
    else:
        temp =pretrain_list
        #圖片小於4各，假設至少會有一個
        for i in range(target_len-len_of_list):
            temp.append(pretrain_list[0])
        return temp,len_of_list

def predict(image_list):
    
    classes=[]
    
    for img in image_list:
        img = tf.transpose(img, [2, 0, 1])
        y_prob=model.predict(img)
        y_classes = y_prob.argmax(axis=-1)
        classes.append(y_classes[0])
    return classes

def predict_full(image):
    model = load_model('old model/image_0.981_weights_best.hdf5')
    image=image.reshape(1,39,135,3)
    classes=[]
    # img = tf.transpose(image, [0,3, 1, 2])
    # print(img.shape)
    y_prob=model.predict(image)
    for label in y_prob:
        y_classes = label.argmax(axis=-1)
        classes.append(y_classes[0])
    return classes

def main_exc(image_list):
    num_list=[]
    trainX_list=[]
    #拿出測試的資料
    #輸出格式 x&y 都是array 
    # x_test, y_test = get_data()
    x_test=image_list
    #資料消除造點 &灰階 &並二值化
    x_test = clean_noise(x_test)
    black_x_test=gray_thresh(x_test)
    medium_x_test,edge_of_text= clean_noise_black(black_x_test)

#      imshow(medium_x_test[0])
#資料消除橫線 => 經過以上步驟，效果不錯所以不做這個，有需要可以參考下面網址，用回歸去除弧線
#https://www.youtube.com/watch?v=4DHcOPSfC4c
#資料切割成不同字
    for i in range(len(medium_x_test)):
        split_image_array=split_picture(medium_x_test[i],edge_of_text[i])
        #整理切割字串，fixed_size=4 , 多的刪掉，少的補齊
        fixed_image_list,length=arrange_split_array(split_image_array)    
        trainX_list.append(fixed_image_list)
        num_list.append(length)
        
        #不同文字分別預測
        for image_list in trainX_list:
            predict_res=''
            result = predict(image_list)
            
        #整合預測結果
        for label in result:
            predict_res=predict_res+label_chr[label]
        print(predict_res)
        return predict_res
def main_exc_fullImage():
##測試整張圖predict
    num_list=[]
    trainX_list=[]
    #拿出測試的資料
    #輸出格式 x&y 都是array 
    # x_test, y_test = get_data()
    x_test, y_test =get_data_generate()
    imshow(x_test[0])
    print(x_test[0].shape)
    #資料消除造點 &灰階 &並二值化
    # x_test = clean_noise(x_test)
    # black_x_test=gray_thresh(x_test)
    # medium_x_test,edge_of_text= clean_noise_black(black_x_test)
    # imshow(edge_of_text[19])
    
    #資料消除橫線 => 經過以上步驟，效果不錯所以不做這個，有需要可以參考下面網址，用回歸去除弧線
    #https://www.youtube.com/watch?v=4DHcOPSfC4c
    time=0
    #資料切割成不同字
    for i in range(len(x_test)):
        image=x_test[i]
        predict_res=''
        result = predict_full(image)

        #整合預測結果
        for label in result:
            
            predict_res=predict_res+label_chr[label]
        print('Target',y_test[time])
        print('Predict',i,' :',predict_res)
        print()
        
        time+=1
def url_to_image(url):

    response = requests.get(url)
    img = Image.open(BytesIO(response.content))
    img.show()
    return img
def base64_to_image(base64_str):
    base64_data = re.sub('^data:image/.+;base64,', '', base64_str)
    binary_data = base64.b64decode(base64_data)
    img_data = BytesIO(binary_data)
    img = Image.open(img_data).convert("RGB")
    return img
@app.route('/predict_image', methods=['GET'])
def predict_image():
    image_list=[]
    
    if request.method == 'GET':
        if request.args.get('datetime'):
            
            token = request.args.get('datetime')
            print("https://nportal.ntut.edu.tw/authImage.do?datetime="+token+"");
            image = url_to_image("https://nportal.ntut.edu.tw/authImage.do?datetime="+token+"")
            #輸入image進function
            print(image)
            image_list.append(np.array(image).reshape(39,135,3))
            predict_res=main_exc(image_list)
            
            #輸出authcode
            resp = Response(response=predict_res,status=200,content_type='text/html;charset=utf-8')
            resp.headers['Access-Control-Allow-Origin'] = '*'
            resp.headers['Access-Control-Allow-Headers'] = 'Origin, X-Requested-With, Content-Type, Accept'
            
            return resp
@app.route('/predict_image_url', methods=['POST'])
def predict_image3():
    image_list=[]
    
    if request.method == 'POST':
        if request.form.get('Url'):
            url = request.form.get('Url')  
            image = base64_to_image(url)
            print(image)
            image_list.append(np.array(image).reshape(39,135,3))
            predict_res=main_exc(image_list)
            
            #輸出authcode
            resp = Response(response=predict_res,status=200,content_type='text/html;charset=utf-8')
            resp.headers['Access-Control-Allow-Origin'] = '*'
            resp.headers['Access-Control-Allow-Headers'] = 'Origin, X-Requested-With, Content-Type, Accept'
            
            return resp
    
@app.route('/predict_image', methods=['POST'])
def predict_image2():
    print('hi')
    image_list=[]
    if request.method == 'POST':
        #print(request.files.get('image'))
        #f = request.files.get('file')
        #if f is None:
        #    return jsonify({"Status": "Error 0000", "Msg": "没有上传图片，请重新上传!"})
        # Image info
        img_file = request.files['image'].read()
                    # 將圖片轉成 PIL 可以使用的格式
        image = Image.open(img_file)
        image_list.append(np.array(image).reshape(39,135,3))
        predict_res=main_exc(image_list)
        
        resp = Response(response=predict_res,status=200,content_type='text/html;charset=utf-8')
        resp.headers['Access-Control-Allow-Origin'] = '*'
        resp.headers['Access-Control-Allow-Headers'] = 'Origin, X-Requested-With, Content-Type, Accept'
        
        return resp
   
    
@app.route('/')
def hello():
    return "Hello World!"

#main_exc_fullImage()
CORS(app)
if __name__ == "__main__":
    model = load_model('old model/0.97187_weights.best.hdf5')
    app.run(port="80")
