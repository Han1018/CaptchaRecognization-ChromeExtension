{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predict_webAPI","provenance":[],"collapsed_sections":[],"mount_file_id":"13TDy2orMf8u08OPjpH3Z2MD-HxYgkNq5","authorship_tag":"ABX9TyMjUaGD5uXHuvYEAwKkXRg5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HZXEjkapCaXO","executionInfo":{"status":"ok","timestamp":1610698677907,"user_tz":-480,"elapsed":789,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["# !pip install captcha\r\n","# !pip install pillow"],"execution_count":1017,"outputs":[]},{"cell_type":"code","metadata":{"id":"77MQG_aNRh29","executionInfo":{"status":"ok","timestamp":1610698678150,"user_tz":-480,"elapsed":1023,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["import uuid\r\n","from matplotlib.pyplot import imshow\r\n","import matplotlib.pyplot as plt\r\n","import os\r\n","import time\r\n","import numpy as np  \r\n","from PIL import Image  \r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.preprocessing import StandardScaler\r\n","import glob \r\n","import datetime\r\n","import cv2\r\n","from keras.models import load_model\r\n","import tensorflow as tf\r\n","from flask import Flask, jsonify, request\r\n","# from captcha.image import ImageCaptcha\r\n","import random\r\n","import string\r\n","from PIL import Image, ImageDraw, ImageFont\r\n","app = Flask(__name__)"],"execution_count":1018,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHtsKGvK018e","executionInfo":{"status":"ok","timestamp":1610698678150,"user_tz":-480,"elapsed":1016,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["ALPHABET = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\r\n","all_set=ALPHABET#+alphabet\r\n","dict_all={}\r\n","label_chr={}\r\n","for i, c in enumerate(all_set):\r\n","  dict_all[c]=i\r\n","CHAR_SET_LEN=len(all_set)\r\n","for i in range(CHAR_SET_LEN):\r\n","  label_chr[i]=all_set[i]\r\n"],"execution_count":1019,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-NrftNfkvvC","executionInfo":{"status":"ok","timestamp":1610698679010,"user_tz":-480,"elapsed":1870,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["class Captcha(object):\r\n","    # 生成幾位數的驗證碼\r\n","    number = 1\r\n","    # 驗證碼圖片的高度和寬度\r\n","    size = (135, 39)\r\n","    # 驗證碼字體大小\r\n","    fontsize = 32\r\n","    #加入幹擾線條數\r\n","    line_number = 2\r\n","\r\n","    #構建一個驗證碼源文本\r\n","    SOURCE = list(string.ascii_uppercase)\r\n","    # for index in range(0, 10):\r\n","    #     SOURCE.append(str(index))\r\n","\r\n","    #用來繪制幹擾線\r\n","    @classmethod\r\n","    def __gene_line(cls, draw, width, height):\r\n","        begin = (random.randint(width*-1, width), random.randint(height*-1, height))\r\n","        end = (random.randint(int(width/2), width), random.randint(0, height))\r\n","        draw.line([begin, end], fill=cls.__gene_random_color(), width=3)\r\n","\r\n","    # 用來繪制幹擾點\r\n","    @classmethod\r\n","    def __gene_points(cls, draw, point_chance, width, height):\r\n","        chance = min(100, max(0, int(point_chance))) #大小限制在[0, 100]\r\n","        for w in range(width):\r\n","            for h in range(height):\r\n","                tmp = random.randint(0, 100)\r\n","                if tmp > 100 - chance:\r\n","                    draw.point((w, h), fill=cls.__gene_random_color())\r\n","\r\n","    # 生成隨機的顏色\r\n","    @classmethod\r\n","    def __gene_random_color(cls, start=0, end=255):\r\n","        random.seed()\r\n","        return (random.randint(0, 230),random.randint(0, 230), random.randint(0, 230), random.randint(start, end))\r\n","\r\n","    # 生成隨機的文字顏色\r\n","    @classmethod\r\n","    def __gene_random_font_color(cls, start=0, end=255):\r\n","        random.seed()\r\n","        return (random.randint(0, 50),random.randint(0, 50), random.randint(0, 50), random.randint(start, end))\r\n","\r\n","    # 隨機選擇一個字體\r\n","    @classmethod\r\n","    def __gene_random_font(cls):\r\n","        fonts = ['Times-Bold.ttf']\r\n","        font = random.choice(fonts)\r\n","        return '/content/drive/MyDrive/ProJ_Proofnum/font/' + font\r\n","\r\n","    # 用來隨機生成一個字符串\r\n","    @classmethod\r\n","    def gene_text(cls, number):\r\n","        #num是生成驗證碼的位數\r\n","        return ''.join(random.sample(cls.SOURCE, number))\r\n","\r\n","    # 生成驗證碼\r\n","    @classmethod\r\n","    def gene_graph_captcha(cls):\r\n","        #驗證碼圖片的高和寬\r\n","        width, height = cls.size\r\n","\r\n","        #驗證碼的字體\r\n","        font = ImageFont.truetype(cls.__gene_random_font(), cls.fontsize)\r\n","        \r\n","        #創建圖片\r\n","        image = Image.new('RGBA', (width,height),cls.__gene_random_color(50, 80))\r\n","        \r\n","        #創建畫筆\r\n","        draw = ImageDraw.Draw(image)\r\n","        #繪制幹擾線\r\n","        for x in range(0, random.randint(4,6)):\r\n","            cls.__gene_line(draw, width, height)\r\n","        all_text=''\r\n","        #創建字體\r\n","        for i in range(4):\r\n","          #生成字符串\r\n","          text = cls.gene_text(cls.number)\r\n","          all_text+=text\r\n","          #獲取字體尺寸\r\n","          font_width, font_height = font.getsize(text)\r\n","\r\n","          #生成文字透明背板\r\n","          blank = Image.new('RGBA',(font_width,font_height))\r\n","          #生成文字畫部\r\n","          temp = ImageDraw.Draw(blank)\r\n","          #寫字\r\n","          temp.text((0,0),text,font=font,fill=cls.__gene_random_font_color(200, 250))\r\n","          #文字背板旋轉\r\n","          ram_angle=random.randint(-20,20)\r\n","          rotated_txt=blank.rotate(ram_angle, resample=Image.BILINEAR,expand=1)\r\n","          #貼到驗證碼整張背板上\r\n","          ram_width=random.randint(-8,8)\r\n","          ram_height=random.randint(-2,2)\r\n","          image.paste(rotated_txt,(13+i*(2+27)+ram_width, int((height-font_height)/2)+ram_height),rotated_txt)\r\n","          #填充字符串\r\n","          # draw.text(((width - 15font_width) / (4-i), (height - font_height) / 2), text, font=font,\r\n","          #           fill=cls.__gene_random_color(0, 255))\r\n","          # if (font_width<27):\r\n","          #   draw.text((15+i*(5+font_width), (height - font_height) / 2), text, font=font,\r\n","          #             fill=cls.__gene_random_color(0, 255))\r\n","          # else:\r\n","          # draw.text((13+i*(2+27)+ram_width, ((height-font_height)/2)+ram_height), text, font=font,\r\n","          #           fill=cls.__gene_random_color(0, 255))\r\n","          \r\n","        # imshow(np.asarray(blank))\r\n","        #繪制噪點\r\n","        cls.__gene_points(draw, 2, width, height)\r\n","        #RGBA 轉 RGB\r\n","        image = image.convert('RGB')\r\n","        return (all_text, image)"],"execution_count":1020,"outputs":[]},{"cell_type":"code","metadata":{"id":"qUKs7cY6RlDD","executionInfo":{"status":"ok","timestamp":1610698679011,"user_tz":-480,"elapsed":1864,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def remove_edge_picture(imagepath):\r\n"," \r\n","  image = cv2.imread(imagepath, 0)\r\n","  # cv2.imshow('原',image)\r\n","  height, width = image.shape\r\n","  corner_list = [image[0,0] < 127,\r\n","                  image[height-1, 0] < 127,\r\n","                  image[0, width-1]<127,\r\n","                  image[ height-1, width-1] < 127\r\n","                  ]\r\n","  if sum(corner_list) >= 3:\r\n","      os.remove(imagepath)\r\n","      return 1\r\n","  return 0\r\n"],"execution_count":1021,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyTGQhFORn4l","executionInfo":{"status":"ok","timestamp":1610698679011,"user_tz":-480,"elapsed":1858,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def resplit_with_parts(image, parts):\r\n","#    image = cv2.imread(imagepath, 0)\r\n","    height, width = image.shape\r\n","    split_image=[]\r\n","    # 将图片重新分裂成parts部分\r\n","    step = width//parts     # 步长\r\n","    start = 0             # 起始位置\r\n","    \r\n","    #只留第一個其他步要\r\n","    for i in range(parts):\r\n","        split_image.append(image[:, start:start+step])\r\n","        start += step\r\n","        \r\n","    return split_image\r\n","  "],"execution_count":1022,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAfh0jv0RqDp","executionInfo":{"status":"ok","timestamp":1610698679012,"user_tz":-480,"elapsed":1852,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def resplit(image):\r\n","#    image = cv2.imread(connect_image, 0)\r\n","    #沒找到圖片就返回\r\n","    split_image=[]\r\n","    part=1\r\n","    if image is None:\r\n","        print('是空的')\r\n","        return\r\n","    height, width = image.shape\r\n","    #4個黏在一起\r\n","    if width >= 85:    \r\n","        part=4\r\n","    #3個黏在一起    \r\n","    elif width >= 55:\r\n","        part=3\r\n","    #2個黏在一起        \r\n","    elif width >= 35:\r\n","        part=2     \r\n","    else:\r\n","        split_image.append(image)\r\n","        return split_image,part\r\n","\r\n","    split_image=resplit_with_parts(image, part)        \r\n","    return split_image,part"],"execution_count":1023,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dC6IzHjRuMi","executionInfo":{"status":"ok","timestamp":1610698679012,"user_tz":-480,"elapsed":1846,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def sort_contours(cnts, method=\"left-to-right\"):\r\n","  # initialize the reverse flag and sort index\r\n","  reverse = False\r\n","  i = 0\r\n","\r\n","  # handle if we need to sort in reverse\r\n","  if method == \"right-to-left\" or method == \"bottom-to-top\":\r\n","      reverse = True\r\n","\r\n","  # handle if we are sorting against the y-coordinate rather than\r\n","  # the x-coordinate of the bounding box\r\n","  if method == \"top-to-bottom\" or method == \"bottom-to-top\":\r\n","      i = 1\r\n","\r\n","  # construct the list of bounding boxes and sort them from top to\r\n","  # bottom\r\n","  boundingBoxes = [cv2.boundingRect(c) for c in cnts]\r\n","  (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\r\n","      key=lambda b:b[1][i], reverse=reverse))\r\n","\r\n","  # return the list of sorted contours and bounding boxes\r\n","  return (cnts)\r\n","\r\n"],"execution_count":1024,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrF_0OYCRxMP","executionInfo":{"status":"ok","timestamp":1610698679012,"user_tz":-480,"elapsed":1840,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def split_picture(image,edge_image):\r\n","    PIC_LENGTH=32\r\n","    label_index=0\r\n","    return_split=[]\r\n","    last_X=0\r\n","    last_Y=0\r\n","    # imshow(image)\r\n","    # 用edge_detect的影像 做圖像分割判斷，提取单个字符\r\n","    contours, hierarchy = cv2.findContours(edge_image,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\r\n","#    print(len(contours))\r\n","    #對返回的各點座標執行排序\r\n","    contours=sort_contours(contours, method=\"left-to-right\")\r\n","    times=0\r\n","    for i, cnt in enumerate(contours):\r\n","        # 最小的外接矩形\r\n","        x, y, w, h = cv2.boundingRect(cnt)\r\n","        \r\n","        #檢測座標點不是空的&& 不能與前一個座標長寬重複(用edge_image找分割點，目前會有重複文提)\r\n","        if (x != 0) and (y != 0) and (last_X!=x or last_Y!=y) :\r\n","            last_X=x\r\n","            last_Y=y\r\n","            part_image=image[y:y+h, x:x+w]\r\n","            height, width = part_image.shape\r\n","            \r\n","            #排除雜訊可能 => width<=20 & height <=20 or height<=14\r\n","            if(width <=20 and height<=20 or height<=14):\r\n","                continue\r\n","            \r\n","            #切割圖片，包含黏在一起的。\r\n","            #返回的part:圖片個數(int), split_image為[]，放圖片的np array。\r\n","            split_image,part=resplit(part_image)\r\n","            \r\n","            for i in range(part):\r\n","                resize_image=cv2.resize(split_image[i],(PIC_LENGTH,PIC_LENGTH))\r\n","                resize_image=resize_image.reshape(PIC_LENGTH,PIC_LENGTH,1)\r\n","                \r\n","                label_index=times\r\n","                #圖片放置到 各字的資料夾\r\n","                try:\r\n","                  #將切割資料分別加入LIST\r\n","                  return_split.append(resize_image)\r\n","#                  cv2.imwrite('./test_splited_pic/{}__{}.jpg'.format(label_index,uuid.uuid1()), split_image[i])\r\n","                  times+=1\r\n","                except :\r\n","                  print('err',times)\r\n","    return return_split\r\n"],"execution_count":1025,"outputs":[]},{"cell_type":"code","metadata":{"id":"zS-mucQXRy_H","executionInfo":{"status":"ok","timestamp":1610698679013,"user_tz":-480,"elapsed":1835,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def readFile_txt(textUrl):\r\n","    f= open(textUrl, mode='r')\r\n","    return f.read()\r\n"],"execution_count":1026,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bsNzSz5CC_-","executionInfo":{"status":"ok","timestamp":1610698679013,"user_tz":-480,"elapsed":1829,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def random_captcha_text(char_set=all_set,captcha_size=4):\r\n","    captcha_text=''\r\n","    for i in range(captcha_size):\r\n","        c=random.choice(char_set)\r\n","        captcha_text+=c\r\n","    return captcha_text"],"execution_count":1027,"outputs":[]},{"cell_type":"code","metadata":{"id":"05qCLObvCA_Z","executionInfo":{"status":"ok","timestamp":1610698679013,"user_tz":-480,"elapsed":1824,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def gen_captcha_text_image(captcha_text):\r\n","    image=ImageCaptcha(width=135,height=39)\r\n","#    captcha_text=random_captcha_text()\r\n","    captcha_text=''.join(captcha_text)\r\n","    captcha=image.generate(captcha_text)\r\n","    captcha_image=Image.open(captcha)\r\n","    captcha_image=np.array(captcha_image)\r\n","    return captcha_image"],"execution_count":1028,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4SmuDg1CE8D","executionInfo":{"status":"ok","timestamp":1610698679014,"user_tz":-480,"elapsed":1818,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def get_data_generate():\r\n","    count=20\r\n","    errtime=0\r\n","    text_list=[]\r\n","    image_list=[]\r\n","    for i in range(count):\r\n","      text = random_captcha_text()\r\n","      image=gen_captcha_text_image(text)\r\n","      #將PIL格式的image轉成CV2的圖片格式\r\n","      image=np.asarray(image)\r\n","      image_list.append(image)\r\n","      text_list.append(text)\r\n","    \r\n","    return image_list,text_list"],"execution_count":1029,"outputs":[]},{"cell_type":"code","metadata":{"id":"_U-Ygoj8ki_u","executionInfo":{"status":"ok","timestamp":1610698679014,"user_tz":-480,"elapsed":1813,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def get_data_myCaptcha():\r\n","    count=5\r\n","    errtime=0\r\n","    text_list=[]\r\n","    image_list=[]\r\n","    for i in range(count):\r\n","      text, image = Captcha.gene_graph_captcha()\r\n","      #將PIL格式的image轉成CV2的圖片格式\r\n","      image=np.asarray(image)\r\n","      image_list.append(image)\r\n","      text_list.append(text)\r\n","    \r\n","    return image_list,text_list"],"execution_count":1030,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9PLsgfARz1s","executionInfo":{"status":"ok","timestamp":1610698679014,"user_tz":-480,"elapsed":1807,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def get_data():\r\n","    test_data_count =20\r\n","    x=[]\r\n","    y=[]\r\n","    i=0\r\n","    pic_route='/content/drive/MyDrive/ProJ_Proofnum/train/'\r\n","  \r\n","    #抓出檔案的圖片&label\r\n","    for i in range(test_data_count):\r\n","        file_image=pic_route+str(i)+'.jpg'\r\n","        if(i==test_data_count):\r\n","            break\r\n","        x.append(np.array(Image.open(file_image)).reshape(39,135,3))\r\n","        # y.append(readFile_txt(file_label))\r\n","        i=i+1\r\n","\r\n","    return x , y"],"execution_count":1031,"outputs":[]},{"cell_type":"code","metadata":{"id":"_64Q7OcuR2en","executionInfo":{"status":"ok","timestamp":1610698679014,"user_tz":-480,"elapsed":1801,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def clean_noise(data_list):\r\n","#    src:https://blog.csdn.net/qq_38410428/article/details/93046099\r\n","    for i in range(len(data_list)):\r\n","        #消除造點的參數皆為預設，細節看上面的網址\r\n","        data_list[i]=cv2.fastNlMeansDenoisingColored(data_list[i],None,10,10,7,21)\r\n","    return data_list\r\n"],"execution_count":1032,"outputs":[]},{"cell_type":"code","metadata":{"id":"7XByEdThR5oZ","executionInfo":{"status":"ok","timestamp":1610698679015,"user_tz":-480,"elapsed":1796,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def clean_noise_black(data_list):\r\n","    # 設置卷積核 \r\n","    kernel1 = np.ones((2, 2), np.uint8)\r\n","    edge_kernel = np.ones((2, 2), np.uint8) \r\n","    edge_list=[]\r\n","    for i in range(len(data_list)):\r\n","#        消除造點的參數皆為預設，細節看上面的網址\r\n","        data_list[i]=cv2.medianBlur(data_list[i], 3)\r\n","#        data_list[i]=cv2.medianBlur(data_list[i], 3)\r\n","#        原文網址：https://kknews.cc/code/63qzkxl.html\r\n","        data_list[i]= cv2.morphologyEx(data_list[i], cv2.MORPH_OPEN, kernel1)\r\n","        data_list[i]= cv2.morphologyEx(data_list[i], cv2.MORPH_CLOSE, kernel1)\r\n","        edge_list.append(cv2.morphologyEx(data_list[i], cv2.MORPH_GRADIENT, edge_kernel))\r\n","    \r\n","    return data_list,edge_list\r\n"],"execution_count":1033,"outputs":[]},{"cell_type":"code","metadata":{"id":"97X1FKAkR7kT","executionInfo":{"status":"ok","timestamp":1610698679015,"user_tz":-480,"elapsed":1790,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def gray_thresh(data_list):\r\n","    \r\n","    for k in range(len(data_list)):\r\n","        # 將圖片轉灰階\r\n","        gray = cv2.cvtColor(data_list[k], cv2.COLOR_BGR2GRAY)\r\n","        # print(gray.shape)\r\n","        # gray = gray.reshape(39,135,1)\r\n","        # 将图片的边缘变为白色\r\n","        height, width = gray.shape\r\n","        for i in range(width):\r\n","            gray[0, i] = 255\r\n","            gray[height-1, i] = 255\r\n","        for j in range(height):\r\n","            gray[j, 0] = 255\r\n","            gray[j, width-1] = 255\r\n","            \r\n","        # 圖片經thresh成黑白\r\n","        #用 OTSU threshold 自訂義閥值, 所以不用指定\r\n","        ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)  #方法选择为THRESH_OTSU\r\n","        #185 is threshhold, 255 is highest value\r\n","#        ret,thresh1 = cv2.threshold(gray, 185, 255, cv2.THRESH_BINARY)\r\n","        data_list[k]=thresh1\r\n","        \r\n","    return data_list\r\n"],"execution_count":1034,"outputs":[]},{"cell_type":"code","metadata":{"id":"EW3-i0KTR_NO","executionInfo":{"status":"ok","timestamp":1610698679015,"user_tz":-480,"elapsed":1782,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def arrange_split_array(pretrain_list):\r\n","    target_len=4\r\n","    len_of_list=len(pretrain_list)\r\n","    if(len_of_list==target_len):\r\n","        return pretrain_list[:],target_len\r\n","    \r\n","    elif(len_of_list>target_len):\r\n","        return pretrain_list[:target_len],len_of_list\r\n","    \r\n","    else:\r\n","        temp =pretrain_list\r\n","        #圖片小於4各，假設至少會有一個\r\n","        for i in range(target_len-len_of_list):\r\n","            temp.append(pretrain_list[0])\r\n","        return temp,len_of_list"],"execution_count":1035,"outputs":[]},{"cell_type":"code","metadata":{"id":"UH6K47uZR_vF","executionInfo":{"status":"ok","timestamp":1610698679289,"user_tz":-480,"elapsed":2051,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def predict(image_list):\r\n","    model = load_model('/content/drive/MyDrive/ProJ_Proofnum/old model/0.97187_weights.best.hdf5')\r\n","    classes=[]\r\n","    \r\n","          \r\n","    for img in image_list:\r\n","        \r\n","        img = tf.transpose(img, [2, 0, 1])\r\n","        y_prob=model.predict(img)\r\n","        y_classes = y_prob.argmax(axis=-1)\r\n","        classes.append(y_classes[0])\r\n","    return classes"],"execution_count":1036,"outputs":[]},{"cell_type":"code","metadata":{"id":"blSUnlvK-1nw","executionInfo":{"status":"ok","timestamp":1610698679290,"user_tz":-480,"elapsed":2045,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def predict_full(image):\r\n","    model = load_model('/content/drive/MyDrive/ProJ_Proofnum/old model/myCaptcha_weights_0.992_best.hdf5')\r\n","    image=image.reshape(1,39,135,3)\r\n","    classes=[]\r\n","    # img = tf.transpose(image, [0,3, 1, 2])\r\n","    # print(img.shape)\r\n","    y_prob=model.predict(image)\r\n","    for label in y_prob:\r\n","      y_classes = label.argmax(axis=-1)\r\n","      classes.append(y_classes[0])\r\n","    return classes"],"execution_count":1037,"outputs":[]},{"cell_type":"code","metadata":{"id":"eK1tEAYFSB5v","executionInfo":{"status":"ok","timestamp":1610698679290,"user_tz":-480,"elapsed":2039,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["\r\n","def main_exc(image_list):\r\n","      num_list=[]\r\n","      trainX_list=[]\r\n","      #拿出測試的資料\r\n","      #輸出格式 x&y 都是array \r\n","      x_test, y_test = get_data()\r\n","      # x_test=image_list\r\n","      #資料消除造點 &灰階 &並二值化\r\n","      x_test = clean_noise(x_test)\r\n","      black_x_test=gray_thresh(x_test)\r\n","      medium_x_test,edge_of_text= clean_noise_black(black_x_test)\r\n","      # imshow(edge_of_text[0])\r\n","      \r\n","#      imshow(medium_x_test[0])\r\n","      \r\n","      #資料消除橫線 => 經過以上步驟，效果不錯所以不做這個，有需要可以參考下面網址，用回歸去除弧線\r\n","      #https://www.youtube.com/watch?v=4DHcOPSfC4c\r\n","      \r\n","      #資料切割成不同字\r\n","      for i in range(len(medium_x_test)):\r\n","          split_image_array=split_picture(medium_x_test[i],edge_of_text[i])\r\n","          #整理切割字串，fixed_size=4 , 多的刪掉，少的補齊\r\n","          fixed_image_list,length=arrange_split_array(split_image_array)  \r\n","          trainX_list.append(fixed_image_list)\r\n","          num_list.append(length)\r\n","      times=0\r\n","      #不同文字分別預測\r\n","      for image_list in trainX_list:\r\n","        predict_res=''\r\n","        result = predict(image_list)\r\n","        \r\n","        #整合預測結果\r\n","        for label in result:\r\n","          predict_res=predict_res+label_chr[label]\r\n","        print(times,': ',predict_res)\r\n","        times+=1"],"execution_count":1038,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-DVNC_8SIdX","executionInfo":{"status":"ok","timestamp":1610698679290,"user_tz":-480,"elapsed":2032,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["def main_exc_fullImage():\r\n","  ##測試整張圖predict\r\n","      num_list=[]\r\n","      trainX_list=[]\r\n","      #拿出測試的資料\r\n","      #輸出格式 x&y 都是array \r\n","      x_test, y_test = get_data()\r\n","      # x_test, y_test =get_data_myCaptcha()\r\n","      # imshow(x_test[0])\r\n","      print(x_test[0].shape)\r\n","      #資料消除造點 &灰階 &並二值化\r\n","      # x_test = clean_noise(x_test)\r\n","      # black_x_test=gray_thresh(x_test)\r\n","      # medium_x_test,edge_of_text= clean_noise_black(black_x_test)\r\n","      # imshow(edge_of_text[19])\r\n","      \r\n","      #資料消除橫線 => 經過以上步驟，效果不錯所以不做這個，有需要可以參考下面網址，用回歸去除弧線\r\n","      #https://www.youtube.com/watch?v=4DHcOPSfC4c\r\n","      time=0\r\n","      #資料切割成不同字\r\n","      for i in range(len(x_test)):\r\n","        image=x_test[i]\r\n","        predict_res=''\r\n","        result = predict_full(image)\r\n","\r\n","        #整合預測結果\r\n","        for label in result:\r\n","          predict_res=predict_res+label_chr[label]\r\n","        # print('Target',y_test[time])\r\n","        print('Predict',i,' :',predict_res)\r\n","        print()\r\n","        \r\n","        time+=1"],"execution_count":1039,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugX0e1x06Atl","executionInfo":{"status":"ok","timestamp":1610698679291,"user_tz":-480,"elapsed":2027,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["@app.route('/predict_image', methods=['POST'])\r\n","def predict_image():\r\n","  print('hi')\r\n","  image_list=[]\r\n","  if request.method == 'POST':\r\n","    if request.files.get('image'):\r\n","      # 從 flask request 中讀取圖片（byte str）\r\n","      image = request.files['image'].read()\r\n","      # 將圖片轉成 PIL 可以使用的格式\r\n","      image = Image.open(io.BytesIO(image))\r\n","      image_list.append(np.array(image).reshape(39,135,3))\r\n","      predict_res=main_exc(image_list)\r\n","      response={\"predict\":predict_res}\r\n","      return jsonify(response)"],"execution_count":1040,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ed6Yvg8_4ZC","executionInfo":{"status":"ok","timestamp":1610698679291,"user_tz":-480,"elapsed":2021,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["@app.route('/')\r\n","def hello():\r\n","    return \"Hello World!\""],"execution_count":1041,"outputs":[]},{"cell_type":"code","metadata":{"id":"2x-Qs3zPAR9V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610698687993,"user_tz":-480,"elapsed":10717,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}},"outputId":"196d8327-cb50-4e52-bb5a-1a3092781e2e"},"source":["main_exc_fullImage()"],"execution_count":1042,"outputs":[{"output_type":"stream","text":["(39, 135, 3)\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd8f6f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 0  : OCUS\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc38eff730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 1  : YNZZ\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbe0203a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 2  : TNOS\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd8f59bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 3  : CCKS\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd858ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 4  : LCKX\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbe0214400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 5  : VMVI\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd8487ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 6  : NMVM\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd84878c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 7  : VSAZ\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbe0081ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 8  : VICA\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd8efb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 9  : GICV\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbe0081a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 10  : OUZI\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc4043a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 11  : ZNAI\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd8442e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 12  : VCVQ\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbe0077510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 13  : ANMO\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbe02032f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 14  : VNNO\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd8f6fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 15  : GCOX\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd97ca598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 16  : CSOJ\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd97c6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 17  : AIMS\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd858f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 18  : UOCS\n","\n","WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbbd858f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predict 19  : NVCV\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"thWO4oE36LhN","executionInfo":{"status":"ok","timestamp":1610698688248,"user_tz":-480,"elapsed":10961,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":["# if __name__ == '__main__':\r\n","#   app.run()"],"execution_count":1043,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_x37ww5AYY6","executionInfo":{"status":"ok","timestamp":1610698688249,"user_tz":-480,"elapsed":10956,"user":{"displayName":"北科大-謝宗翰","photoUrl":"","userId":"04406997407027209794"}}},"source":[""],"execution_count":1043,"outputs":[]}]}